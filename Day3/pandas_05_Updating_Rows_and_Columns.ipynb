{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdfbe52",
   "metadata": {},
   "source": [
    "## Part 5: Updating Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc523dbf",
   "metadata": {},
   "source": [
    "This notebook shows how to **modify DataFrames**: renaming columns, updating values, applying transformations, and adding/removing rows. \\\n",
    "Changing labels and values is how we clean and enrich data. This section shows patterns for renaming, mass-updating, safe assignment, and applying transformations.\n",
    "\n",
    "Core goals:\n",
    "\n",
    "- Rename columns globally or partially.\n",
    "- Update specific rows/cells without chained-assignment issues.\n",
    "- Apply string and custom functions to Series/DataFrames.\n",
    "- Use `map` and `replace` for value recoding.\n",
    "- Combine and split columns.\n",
    "- Append and remove rows in controlled ways.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb3906",
   "metadata": {},
   "source": [
    "### 1. Renaming columns in `df_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10ee3a",
   "metadata": {},
   "source": [
    "Clean, consistent column names improve readability and reduce downstream bugs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ebb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = {\n",
    "    \"first\": [\"Alice\", \"Bob\", \"Carol\", \"Sarah\"],\n",
    "    \"last\": [\"Smith\", \"Jones\", \"Lee\", \"Jones\"],\n",
    "    \"email\": [\n",
    "        \"alice@example.com\",\n",
    "        \"bob@example.com\",\n",
    "        \"carol@example.com\",\n",
    "        \"sarah@example.com\",\n",
    "    ],\n",
    "    \"uid\": [\"AS100293\", \"BJ240806\", \"CL150510\", \"SJ251203\"],\n",
    "    \"year\": [1993, 2006, 2010, 2003],\n",
    "    \"age\": [32, 19, 15, 22],\n",
    "}\n",
    "df_small_orig = pd.DataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3caee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a copy that we can freely modify without modifying the original dataframe\n",
    "df_small = df_small_orig.copy()\n",
    "\n",
    "# 1a. Directly replace all column names\n",
    "df_small.columns = [\"first_name\", \"last_name\", \"email_address\", \"id_code\", \"byear\", \"age_2025\"]\n",
    "print(\"After assigning new column list:\")\n",
    "df_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b. Uppercase all column names via list comprehension\n",
    "df_small.columns = [col.upper() for col in df_small.columns]\n",
    "print(\"\\nAfter uppercasing column names:\")\n",
    "df_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeced05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c. Modify names more flexibly: replace underscores with spaces (simulate if needed)\n",
    "# First set back to some with underscores to demo\n",
    "df_small.columns = [col.replace(\"_\", \" \") for col in df_small.columns]\n",
    "print(\"\\nAfter replacing underscores with spaces:\")\n",
    "df_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d. Rename only some columns (partial) using .rename\n",
    "df_small = df_small.rename(columns={\"FIRST NAME\": \"first\", \"LAST NAME\": \"last\"})\n",
    "print(\"\\nAfter selective rename:\")\n",
    "df_small.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09c3f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30896f0",
   "metadata": {},
   "source": [
    "### 2. Updating row values safely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c34a4",
   "metadata": {},
   "source": [
    "These methods perform explicit assignment and avoid ambiguous chained operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6fa877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the original dataframe\n",
    "df_small = df_small_orig.copy()\n",
    "\n",
    "# Update entire row 1 (zero-based index) with new data using .loc\n",
    "df_small.loc[1] = [\"Robert\", \"Jones\", \"robert@example.com\", \"RJ010100\", 2000, 25]\n",
    "print(\"After replacing all of row 1:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07dd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update only some columns in a row\n",
    "df_small.loc[2, [\"email\"]] = [\"carol.modified@example.com\"]\n",
    "print(\"\\nAfter updating only email for row 2:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a single value using .at\n",
    "df_small.at[0, \"last\"] = \"Smythe\"\n",
    "print(\"\\nAfter changing Alice's last name via .at:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f346352",
   "metadata": {},
   "source": [
    "**Warning:**\n",
    "\n",
    "Avoid chained assignment like this (can produce `SettingWithCopyWarning` and unreliable behavior):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f757f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_small[\"last\"] == \"Jones\"\n",
    "# This is unsafe / may not persist:\n",
    "df_small[mask][\"last\"] = \"J.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be371b4",
   "metadata": {},
   "source": [
    "Correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.loc[mask, \"last\"] = \"J.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced8ebb",
   "metadata": {},
   "source": [
    "### 3. String methods on Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad179608",
   "metadata": {},
   "source": [
    "`df[\"email\"].str.lower()` applies lowercase conversion elementwise across the entire column.\n",
    "\n",
    "Vectorized `.str` operations are concise, readable, and usually faster than manual loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppercase/lowercase transformations safely\n",
    "df_small[\"email\"] = df_small[\"email\"].str.lower()  # vectorized lowercase\n",
    "print(\"\\nEmails after lowercasing:\")\n",
    "df_small[\"email\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a20d3",
   "metadata": {},
   "source": [
    "### 4. apply / applymap / map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06dfccd",
   "metadata": {},
   "source": [
    "Where to use each:\n",
    "\n",
    "- `Series.apply(func)`: apply a function to each value in one column.\n",
    "- `DataFrame.apply(func)`: apply a function to each column (or row) as a Series.\n",
    "- `DataFrame.applymap(func)`: apply a function to every cell (elementwise).\n",
    "- `Series.map(mapping_or_func)`: map values using a dictionary or function.\n",
    "\n",
    "These tools are useful because they handle custom transformations when built-in vectorized methods are not enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on a Series: length of each email\n",
    "email_lengths = df_small[\"email\"].apply(len)\n",
    "print(\"\\nLength of each email (Series.apply):\")\n",
    "email_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f076ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply with a user-defined function\n",
    "def shout(email):\n",
    "    return email.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEmail shouted via apply:\")\n",
    "df_small[\"email\"].apply(shout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with lambda\n",
    "print(\"\\nEmail first 5 chars using lambda:\")\n",
    "df_small[\"email\"].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf749f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference: df.apply(len) applies to each column (Series) -> gives number of non-null entries per column\n",
    "print(\"\\nUsing df.apply(len):\")\n",
    "df_small.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applymap applies to every element of the DataFrame\n",
    "print(\"\\nApplying str.lower to every string cell (applymap):\")\n",
    "df_small.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877fbbb3",
   "metadata": {},
   "source": [
    "### 5. map (elementwise with a mapping dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ccf5b",
   "metadata": {},
   "source": [
    "`map` vs `replace` for recoding values\n",
    "\n",
    "- `map({...})` on a Series recodes matching values; unmatched values become `NaN`.\n",
    "- `replace({...})` changes only matched values and keeps unmatched values unchanged.\n",
    "\n",
    "Choose `map` when you want strict remapping, `replace` when you want partial substitution without introducing `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want to abbreviate first names\n",
    "df_small[\"first_abbrev\"] = df_small[\"first\"].map({\"Alice\": \"A.\", \"Robert\": \"R.\", \"Carol\": \"C.\"})\n",
    "print(\"\\nAfter mapping first names to abbreviations:\")\n",
    "df_small[[\"first\", \"first_abbrev\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: unmapped values become NaN; to avoid that, you can fill or use replace\n",
    "df_small[\"first_abbrev_fallback\"] = df_small[\"first\"].replace({\"Alice\": \"A.\", \"Robert\": \"R.\", \"Carol\": \"C.\"})\n",
    "print(\"\\nUsing replace (no NaNs for unmatched since exact replacements):\")\n",
    "df_small[[\"first\", \"first_abbrev_fallback\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f08d93",
   "metadata": {},
   "source": [
    "### 6. Big DataFrame: rename column and use map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1001ab97",
   "metadata": {},
   "source": [
    "This section demonstrates two practical cleaning steps on a large dataset:\n",
    "\n",
    "- Renaming `CompTotal` to `Salary` for clearer semantics.\n",
    "- Mapping country names to short codes (`US`, `CH`, `DE`, ...).\n",
    "\n",
    "These operations make analysis outputs easier to read and standardize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1009b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/survey_results_public.csv\")\n",
    "\n",
    "# Rename 'CompTotal' to 'Salary'\n",
    "df = df.rename(columns={\"CompTotal\": \"Salary\"})\n",
    "print(\"Columns after renaming compensation:\")\n",
    "print([c for c in df.columns if \"Salary\" in c])\n",
    "\n",
    "# Example map usage: create a simplified label for some countries\n",
    "country_abbrev = {\n",
    "    \"United States of America\": \"US\",\n",
    "    \"Switzerland\": \"CH\",\n",
    "    \"Germany\": \"DE\",\n",
    "    \"India\": \"IN\",\n",
    "    \"Canada\": \"CA\",\n",
    "}\n",
    "df[\"country_code\"] = df[\"Country\"].map(country_abbrev)\n",
    "print(\"\\nSample country codes:\")\n",
    "df.loc[df[\"country_code\"].notna(), [\"Country\", \"country_code\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aca604",
   "metadata": {},
   "source": [
    "### 7. Combine first & last into a full name, then split back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7cf1e6",
   "metadata": {},
   "source": [
    "- Combine columns: `df[\"full_name\"] = df[\"first\"] + \" \" + df[\"last\"]`\n",
    "- Remove no-longer-needed columns: `drop(columns=[...])`\n",
    "- Split back with: `.str.split(\" \", expand=True)`\n",
    "\n",
    "Feature engineering often requires building intermediate text fields and then re-normalizing structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into full_name\n",
    "df_small[\"full_name\"] = df_small[\"first\"] + \" \" + df_small[\"last\"]\n",
    "print(\"After combining:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original first & last columns\n",
    "df_small.drop(columns=[\"first\", \"last\"], inplace=True)\n",
    "print(\"\\nAfter dropping first & last:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full_name back into first & last\n",
    "df_small[[\"first\", \"last\"]] = df_small[\"full_name\"].str.split(\" \", expand=True)\n",
    "print(\"\\nAfter splitting full_name:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47719c2",
   "metadata": {},
   "source": [
    "### 8. Appending rows & the ignore\\_index=True quirk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae511",
   "metadata": {},
   "source": [
    "Two common patterns:\n",
    "\n",
    "- `pd.concat([df, new_df], ignore_index=True)` to append one or many rows.\n",
    "- `df.loc[new_index] = {...}` for quick insertion of a single row.\n",
    "\n",
    "Why `ignore_index=True` matters: it rebuilds a clean continuous index after concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f934156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_small_orig.copy()\n",
    "\n",
    "# Add a new row using pd.concat\n",
    "new_row = pd.DataFrame([{\"first\": \"Tony\"}])\n",
    "\n",
    "# Method 1: Concatenate, resetting the index\n",
    "df_small = pd.concat([df_small, new_row], ignore_index=True)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36594d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using .loc to append a new row\n",
    "new_idx = len(df_small)\n",
    "df_small.loc[new_idx] = {\"first\": \"Tony\"}\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aac4c9",
   "metadata": {},
   "source": [
    "### 9. Appending another DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e2b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_small_orig.copy()\n",
    "\n",
    "# Create a smaller DataFrame with same columns\n",
    "new_people = pd.DataFrame({\n",
    "    \"first\": [\"Diana\", \"Eli\"],\n",
    "    \"last\":  [\"Prince\", \"Musk\"],\n",
    "    \"email\": [\"diana@themiscira.com\", \"eli@space.com\"],\n",
    "    \"full_name\": [\"Diana Prince\", \"Eli Musk\"],\n",
    "})\n",
    "\n",
    "# Append new_people to df_small (resetting index for a clean result)\n",
    "df_small = pd.concat([df_small, new_people], ignore_index=True)\n",
    "print(\"\\nCombined DataFrame:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a419b",
   "metadata": {},
   "source": [
    "### 10. Removing rows by index and by condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660d8d2",
   "metadata": {},
   "source": [
    "- `drop(index=...)` removes rows by index label.\n",
    "- Combine with a mask to drop conditionally, e.g. rows where `last == \"Lee\"`.\n",
    "\n",
    "Selective removal is a key cleanup step before statistics or model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a row by its index label, e.g., drop index 1\n",
    "df_small = df_small.drop(index=1)\n",
    "print(\"\\nAfter dropping index=1:\")\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb734a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where last name == \"Lee\"\n",
    "mask_lee = df_small[\"last\"] == \"Lee\"\n",
    "df_no_lee = df_small.drop(index=df_small[mask_lee].index)\n",
    "print(\"\\nAfter dropping rows where last == 'Lee':\")\n",
    "df_no_lee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d3d69",
   "metadata": {},
   "source": [
    "### Exercise for Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486875b",
   "metadata": {},
   "source": [
    "#### Exercise 5.1\n",
    "- Transform every column name so that it starts with an uppercase letter (e.g. `first` → `First`, `email` → `Email`).\n",
    "- Replace each name and last name with the first letter followed by a dot using `apply()`.\n",
    "- Extract the domain (after the `@`) from each email.\n",
    "\n",
    "#### Exercise 5.2\n",
    "- Create an `Adult` column to be `True` when the numeric age is **> 18**, and `False` otherwise (including NaN ages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d2ca2",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424bffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
