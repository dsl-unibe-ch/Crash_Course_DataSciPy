{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LZWsXsoP9xF"
   },
   "source": [
    "# 4) Navigating through dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Numpy has a very good and extensive documentation, which you can find at https://numpy.org/doc/stable/. If you need any further details about numpy arrays, you can always refer to it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-dimensional images as arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import and inspect an multidimensional image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1614342463990,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "9iY_ZQgrTWCa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_multi = skimage.io.imread('https://github.com/guiwitz/microfilm/raw/master/demodata/coli_nucl_ori_ter.tif')\n",
    "\n",
    "image_multi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvPLOmlMTxbY"
   },
   "source": [
    "Now this image has more than just rows and columns of pixels. In total, we have 4 dimensions, the last two corresponding to y and x coordinates. The two first correspond to different channels (3) and time-points (30). If we want to access and plot a partial 2D image, we have to use indexing. For example, let's display the 2nd channel of the 6th time point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1614342547380,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "5nK4mxwlT7ys",
    "outputId": "42055c51-bf26-4294-fb65-2c0a48faed49",
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_singleplane = image_multi[1, 5].copy()\n",
    "\n",
    "plt.imshow(im_singleplane, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we additionally **used the ```copy``` method**. This ensures that whatever modification we make to the cropped version doesn't affect the original image! We will do this often in the future, so it is good to remember."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPNdTPiiTT3A"
   },
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1614342719264,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "LzNYiEOyUaQD",
    "tags": []
   },
   "source": [
    "A common operation is to only consider part of an image for further analysis. We have learned in the previous chapters that we could use slicing to extract only part of an array which for an image is called cropping. For example, we might want to focus on the rows around 110 and columns around 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1614342770460,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "50BgLjoRU4YZ",
    "outputId": "38a89dcc-12e7-48a9-ffbc-83bb1a5247ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_crop = im_singleplane[90:130, 30:70].copy()\n",
    "plt.imshow(im_crop, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nMaz-_DVBhM"
   },
   "source": [
    "We can also check again the size of this cropped image. We expect it to be a square of 40x40 pixels (given the slicing numbers we used above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1614342861395,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "zG3ZfpPdVNzG",
    "outputId": "e3b6038b-a1bc-41af-8757-42dc6caaa0fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_crop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2Bl_00LS9ns"
   },
   "source": [
    "### Operations on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the operations we have seen for arrays in general are of course still valid for images. So we can do simple calculus or apply functions to images. Let's first print the cropped image again and then see how the operations change the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1614343056796,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "63RxqWJCSj6Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_crop + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_crop * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(im_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kONcD-Fo-AzN"
   },
   "source": [
    "### Projections (aggregating functions over dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When handling images, the ```min```, ```max``` are very relevant as they implement the common **projections** that one often performs on multi-dimensional data. For example we can project all time-points on a single plane using mean intensity projection. Using the original multidimensional image again (remember that we did not change it since we always created copies to manipulate), we would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1614343088730,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "g2mXTvba-VSH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_proj = np.mean(image_multi, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have aggregated over the time dimension, we now have a 3D image (2 spatial dimensions plus channels). The time-axis has been compressed to a single plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1614343089966,
     "user": {
      "displayName": "Guillaume Witz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgT0K2JVYzEsjzsS5nhkUVjUrSIJ5jHzXnBoYrmVf8=s64",
      "userId": "16033870147214403532"
     },
     "user_tz": -60
    },
    "id": "18M7PDlS-WPA",
    "outputId": "a581cf21-9483-4ca0-ce5c-f5bf5c849e11",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the original image:\", image_multi.shape)\n",
    "print(\"Shape after projection:\", im_proj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us display the first channel of the projected image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_proj[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations *between* images/arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any arrays, we can of course also perform operations between images. For example, we could create an image containing \"noise\" and add it to an image. Like this we can test the quality of a denoising algorithm.\n",
    "\n",
    "First we create a noise image with the same shape as the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_noise = np.random.normal(0, 1, im_singleplane.shape)\n",
    "plt.imshow(im_noise, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we simply add the noise image to the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_singleplane_noisy = im_singleplane + im_noise\n",
    "\n",
    "plt.imshow(im_singleplane_noisy, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the standard mathematical operations provided by Numpy, we can apply operations which are specifically designed for images. Such functions are typically provided by libraries like scikit-image.\n",
    "\n",
    "A classical example is the blurring of an image using a Gaussian filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_gauss = skimage.filters.gaussian(im_singleplane, sigma=2, preserve_range=True)\n",
    "plt.imshow(im_gauss, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking/thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have seen that we can create boolean arrays by applying logical operations to arrays. In the world of images, this is typically used to thereshold an image, i.e. extracting only parts of the image which have an intensity higher that a given threshold.\n",
    "\n",
    "For example on the blurred image above, we can extract all pixels which have an intensity higher than 103:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_thresholded = im_gauss > 103\n",
    "im_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we obtain a boolean array that we can still plot using ```imshow``` and that gives us a binary image with bright regions (above 103) shown as white (```True```) and darker ones as black (```False```).\n",
    "\n",
    "With the right threshold value, we can extract the regions of interest in an image - like the cell bodies in this fluorescence image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearranging and extending dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load another image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread(\"https://upload.wikimedia.org/wikipedia/commons/5/5b/Serengeti_Elefantenherde1.jpg?download\")\n",
    "\n",
    "print(\"Shape of the image:\", image.shape)\n",
    "print(\"Data type of the image:\", image.dtype)\n",
    "print(\"Value range of the image:\", image.min(), \"to\", image.max())\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the colour channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in RGB images, the three channels are stored in the last dimension. This is different from the previous image, where the channels were stored in the first dimension. We can rearrange the colour channels by indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_recolor = image[:, :, [2, 1, 0]]\n",
    "plt.imshow(image_recolor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could remove the blue signal by setting it to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_no_blue = image.copy()\n",
    "image_no_blue[:, :, 2] = 0\n",
    "plt.imshow(image_no_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could extract only the red channel, and then stack it again to an RGB image (think about why it is now only gray):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_channel = image[:, :, 0]\n",
    "rgb_only_red = np.stack((red_channel, red_channel, red_channel), axis=-1)\n",
    "\n",
    "plt.imshow(rgb_only_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating the spatial dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's flip the image along the horizontal axis. Instead of using negative steps in slicing, we now use the ```flip``` function from Numpy (sometimes there are multiple ways to one solution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = np.flip(image, axis=0)\n",
    "plt.imshow(flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us concatenate the flipped image with the original one along the horizontal axis. We can use the ```concatenate``` function from Numpy for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.concatenate((image, flipped), axis=0)\n",
    "print(\"Shape of the combined image:\", combined.shape)\n",
    "plt.imshow(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also rotate the original image by 90 degrees by moving the spatial axes around. This is done using the ```moveaxis``` function from Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = np.moveaxis(image, 0, 1)\n",
    "print(\"Shape after reshaping:\", rotated.shape)\n",
    "\n",
    "plt.imshow(rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further\n",
    "\n",
    "Image processing and computer vision is an entire field of research outside the scope of this introductory course. Common next steps are object detection, measurements, tracking etc. For an introduction to image processing you can check the course [Image processing for beginners](https://github.com/guiwitz/PyImageCourse_beginner) on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6qT3vkSVaFi"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercises, you will work on an image that shows a glacier, taken with a satellite, in the years 2021 and 2022. It is an RGB image, i.e. it has 3 channels (red, green and blue).\n",
    "The goal is to do a simple **computational analysis of the image** to answer the question **whether the area of the glacier has changed**.\n",
    "\n",
    "More background information: https://www.copernicus.eu/en/news/news/observer-monitoring-glaciers-space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Load the following image** into a numpy array, print its shape and display the image: https://www.copernicus.eu/sites/default/files/inline-images/Picture6_8.jpg\n",
    "\n",
    "2. **Remove the writing** on the top by saving an image slice beginning from row 70 in a new variable. Display the slice to confirm that we have a good crop.\n",
    "\n",
    "3. Next, we want to analyse the **surface of the glacier**. We consider this to be the **white area** in the image. All pixels that exceed a certain **threshold** shall be considered white. So create a **mask** in which all pixels contain `True` where the pixel value is greater than 200.\n",
    "\n",
    "4. Since we have an RGB image, there are 3 channels (red, green and blue), this also reflects in the shape of the mask created above. With `np.all()` (another aggregating function) we can apply the **mask to all 3 channels together** to extract the white area. More precisely it means that we generate a 2D boolean image that is only `True` where the values are **above the threshold in all 3 channels**. You can then show the result with `plt.imshow()`.\n",
    "\n",
    "    *Hint: use `white = np.all(mask, axis=-1)`*\n",
    "\n",
    "5. (Optional) In many scientific contexts, it is crucial whether **ice areas have a certain minimum size**. To extract these, we can remove small, unconnected areas. We can use the function `skimage.morphology.opening()` for this purpose (for details, see below). Again display the result.\n",
    "\n",
    "    *Hint: use `skimage.morphology.opening(white)`*\n",
    "\n",
    "6. Now split the extracted boolean snow image into a **part showing 2021 and one for 2022**, respectively (just create 2 crops along the middle and save them in variables).\n",
    "\n",
    "7. Calculate the **area of the glacier** in 2021 and 2022 by counting the number of pixels that are `True` in the respective images. You can simply use `np.sum()` for this. Print it and make a **conclusion about the change** in the glacier area.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*Details on `skimage.morphology.opening()`: This function first removes a few pixels from the edge of all areas and then adds the same number of pixels to the result. The effect is that small areas are deleted because after the pixels have been removed there is no area left to which pixels could be added again. The result is a **mask** that only contains areas with a certain minimum size. Even more information you can find in the [documentation](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.opening)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOdi0hW1jeN9bnQ0CiR6Tc",
   "collapsed_sections": [],
   "name": "02-Numpy_arrays.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cp-env02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
